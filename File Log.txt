Game starts at: 2024-10-01T16:00
Creating Map
I created the map in Time: 2 milliseconds

************  Method:  Initialization *********: TAgent
******* Scenario_Number:    --0-- *******
Changed data at the BEGINNING of the method:

Beliefs in GW:
N. UnInhibited Beliefs in GW: 0

Beliefs in LONG MEMORY:
N. Belief in LONG MEMORY: 0
N. Inhibited Beliefs in LONG MEMORY: 0

Goals in GW
N. Goals in GW: 0
N. UnInhibited Goals in GW: 0

Goals in LONG MEMORY
N. Goals in LONG MEMORY: 0
N. Inhibited Goals in LONG MEMORY: 0

Desires in GW
N. Desires in GW: 0

Desires with Options in GW

Intentions in GW
N. Intentions in GW: 0

Regions in GW
N. UnInhibited Routes Region in GW: 0
N. UnInhibited Station Region in GW: 0

Regions in LONG MEMORY
N. All Route Region in LONG MEMORY: 0
N. Inhibited Route Region in LONG MEMORY: 0
N. Station in LONG MEMORY: 0
N. Inhibited Station Region in LONG MEMORY: 0

*************** Work flow in Method ***************
I read predicates, beliefs, functional, green and quality goals
Loaded Goals : [Visit_Paris, Visit_Frankfurt, Visit_Rome]

************  Method:  Initialization *********: TAgent
******* Scenario_Number:    --0-- *******
Changed data at the END of the method:

No data is changed.

************  Method:  Start *********: TAgent
******* Scenario_Number:    --1-- *******
Changed data at the BEGINNING of the method:

No data is changed.
*************** Work flow in Method ***************
Now Agent Status is Active
Working_Cycle; 0

************  Method:  Perception_Processing *********: TWorking_Memory_Maintenance
******* Scenario_Number:    --1-- *******
Changed data at the BEGINNING of the method:

No data is changed.
*************** Work flow in Method ***************
Perception Processing number: 0
I'm feeling some stimulus
Sensor acquires last Perception (if it exists).
The Agent has NOT a stimulus.
Now, the agent checks if it has some goals to promote to desire

************  Method:  AM_Endogenous_Module *********: TE_Switching_Function
******* Scenario_Number:    --1-- *******
Changed data at the BEGINNING of the method:

Beliefs in GW:
N. UnInhibited Beliefs in GW: 0

Beliefs in LONG MEMORY:
N. Belief in LONG MEMORY: 67
N. Inhibited Beliefs in LONG MEMORY: 0

*************** Work flow in Method ***************
I'm promoting the goal to Desire, inside --(List_goals - Inhibited_goals)-- section (see Listing 1). Goal Name: Visit_Paris
Not Promoted Goal Name: Visit_Rome because the precondition Functional Goal is not true
I'm promoting the goal to Desire, inside --(List_goals - Inhibited_goals)-- section (see Listing 1). Goal Name: Visit_Frankfurt
I promoted the goal: Visit_Paris to the Desire: D1
I promoted the goal: Visit_Frankfurt to the Desire: D2

************  Method:  Insert_New_Desires *********: TGlobalWorkspace
******* Scenario_Number:    --1-- *******
Changed data at the BEGINNING of the method:

No data is changed.
*************** Work flow in Method ***************
I inserted new Desires: 2

************  Method:  Insert_New_Desires *********: TGlobalWorkspace
******* Scenario_Number:    --1-- *******
Changed data at the END of the method:

Desires in GW
N. Desires in GW: 2
Desire N. -1 - Named: D1
Desire N. -2 - Named: D2


************  Method:  AM_Endogenous_Module *********: TE_Switching_Function
******* Scenario_Number:    --1-- *******
Changed data at the END of the method:

Beliefs in GW:
N. UnInhibited Beliefs in GW: 67

Beliefs in LONG MEMORY:
N. Belief in LONG MEMORY: 67
N. Inhibited Beliefs in LONG MEMORY: 0


************  Method:  MeansEnd *********: TReasoner_Function
******* Scenario_Number:    --1-- *******
Changed data at the BEGINNING of the method:

Desires in GW
N. Desires in GW: 2
Desire N. -1 - Named: D1
Desire N. -2 - Named: D2

*************** Work flow in Method ***************
Using its Meand-End Reasoner, the agent tries to find some options for any desire.
For the Desire --1-- The Attentional Goal is a:  TFunctional_Goal
Its Final belief type is: Belief_Destination_Station
Agent uses its Means_End_For_Belief_Destination_Station method to search some options

************  Method:  Means_End_For_Belief_Destination_Station *********: TReasoner_Function
******* Scenario_Number:    --1-- *******
Changed data at the BEGINNING of the method:

No data is changed.
*************** Work flow in Method ***************

The Functional_Goal Name is: Visit_Paris
The Functional_Belief is a:  Belief_Destination_Station
I search for a plan for the Desire
I created/found some plan in Time: 963 milliseconds
I found paths: 964968
I found n. paths Before Finally_Formula: 964968
I Apply the Finally Operator
Start time in simulation: 2024-10-01T16:00
Range time in Finally Operator - 2024-10-01T18:00 - 2024-10-01T22:00
I found n. paths After Finally_Formula: 3
Agent inserts actions to do (go to in some routes) in the desire. These can be null.
**** Path Steps ********

****** Path: 1
Route list for the path: [128, 144, 16]

******** New Route: 128 - Departure: Lisboa - Destination: Madrid
Start creating Path Plan:
Precondition.  Station: Lisboa - Route: -1 - Step: 0
Postcondition.  Station: Lisboa - Route: 128 - Step: 3
-------------- Next Step --------------
Precondition.  Station: Lisboa - Route: 128 - Step: 3
Postcondition.  Station: Madrid - Route: -1 - Step: 0
-------------- Next Step --------------

******** New Route: 144 - Departure: Madrid - Destination: Pamplona
Start creating Path Plan:
Precondition.  Station: Madrid - Route: -1 - Step: 0
Postcondition.  Station: Madrid - Route: 144 - Step: 2
-------------- Next Step --------------
Precondition.  Station: Madrid - Route: 144 - Step: 2
Postcondition.  Station: Pamplona - Route: -1 - Step: 0
-------------- Next Step --------------

******** New Route: 16 - Departure: Pamplona - Destination: Paris
Start creating Path Plan:
Precondition.  Station: Pamplona - Route: -1 - Step: 0
Postcondition.  Station: Pamplona - Route: 16 - Step: 2
-------------- Next Step --------------
Precondition.  Station: Pamplona - Route: 16 - Step: 2
Postcondition.  Station: Pamplona - Route: 16 - Step: 4
-------------- Next Step --------------
Precondition.  Station: Pamplona - Route: 16 - Step: 4
Postcondition.  Station: Paris - Route: -1 - Step: 0
-------------- Next Step --------------

****** Path: 3
Route list for the path: [128, 144, 18]

******** New Route: 128 - Departure: Lisboa - Destination: Madrid
Start creating Path Plan:
Precondition.  Station: Lisboa - Route: -1 - Step: 0
Postcondition.  Station: Lisboa - Route: 128 - Step: 3
-------------- Next Step --------------
Precondition.  Station: Lisboa - Route: 128 - Step: 3
Postcondition.  Station: Madrid - Route: -1 - Step: 0
-------------- Next Step --------------

******** New Route: 144 - Departure: Madrid - Destination: Pamplona
Start creating Path Plan:
Precondition.  Station: Madrid - Route: -1 - Step: 0
Postcondition.  Station: Madrid - Route: 144 - Step: 2
-------------- Next Step --------------
Precondition.  Station: Madrid - Route: 144 - Step: 2
Postcondition.  Station: Pamplona - Route: -1 - Step: 0
-------------- Next Step --------------

******** New Route: 18 - Departure: Pamplona - Destination: Paris
Start creating Path Plan:
Precondition.  Station: Pamplona - Route: -1 - Step: 0
Postcondition.  Station: Pamplona - Route: 18 - Step: 2
-------------- Next Step --------------
Precondition.  Station: Pamplona - Route: 18 - Step: 2
Postcondition.  Station: Pamplona - Route: 18 - Step: 4
-------------- Next Step --------------
Precondition.  Station: Pamplona - Route: 18 - Step: 4
Postcondition.  Station: Paris - Route: -1 - Step: 0
-------------- Next Step --------------

****** Path: 5
Route list for the path: [128, 144, 114]

******** New Route: 128 - Departure: Lisboa - Destination: Madrid
Start creating Path Plan:
Precondition.  Station: Lisboa - Route: -1 - Step: 0
Postcondition.  Station: Lisboa - Route: 128 - Step: 3
-------------- Next Step --------------
Precondition.  Station: Lisboa - Route: 128 - Step: 3
Postcondition.  Station: Madrid - Route: -1 - Step: 0
-------------- Next Step --------------

******** New Route: 144 - Departure: Madrid - Destination: Pamplona
Start creating Path Plan:
Precondition.  Station: Madrid - Route: -1 - Step: 0
Postcondition.  Station: Madrid - Route: 144 - Step: 2
-------------- Next Step --------------
Precondition.  Station: Madrid - Route: 144 - Step: 2
Postcondition.  Station: Pamplona - Route: -1 - Step: 0
-------------- Next Step --------------

******** New Route: 114 - Departure: Pamplona - Destination: Paris
Start creating Path Plan:
Precondition.  Station: Pamplona - Route: -1 - Step: 0
Postcondition.  Station: Pamplona - Route: 114 - Step: 2
-------------- Next Step --------------
Precondition.  Station: Pamplona - Route: 114 - Step: 2
Postcondition.  Station: Pamplona - Route: 114 - Step: 4
-------------- Next Step --------------
Precondition.  Station: Pamplona - Route: 114 - Step: 4
Postcondition.  Station: Paris - Route: -1 - Step: 0
-------------- Next Step --------------
N. Options found : 3
Agent found at least an option and it can deliberate
******************** Selected Path **********************: TReasoner_Function
********* PAth: 0
Stations: [Lisboa, Madrid, Pamplona, Paris]
Routes Numbers: [128, 144, 16]
Agent Start Time: 2024-10-01T16:00 - Finally Operator Data: Start_Interval: 2024-10-01T18:00 - End_Interval: 2024-10-01T22:00
Panorama average: 0.6
Locomotive average ( CO2/Route ): 0.7333333333333334
Speed average: 2.3333333333333335
Path Time: 5.833333333333333 - Arrive time: 2024-10-01T21:49
Path Data:
----------------------------
Route Number: 128 - Route_Time: 1.3333333333333333
Route Color: Violet
Total Rounds Route: 2
Departure/Destination: Lisboa-Madrid - Locomotive: Hybrid - Panorama: Fair - Speed: High - N.pieces: 3
Step Number: 3
Locomotive value: 0.5
Locomotive Route value: 1.5
Panorama value: 0.6
Speed value: 3
**********************
Route Number: 144 - Route_Time: 2.0
Route Color: White
Total Rounds Route: 2
Departure/Destination: Madrid-Pamplona - Locomotive: Electric - Panorama: Fair - Speed: Medium - N.pieces: 3
Step Number: 3
Locomotive value: 0.1
Locomotive Route value: 0.30000000000000004
Panorama value: 0.6
Speed value: 2
**********************
Route Number: 16 - Route_Time: 2.5
Route Color: Green
Total Rounds Route: 3
Departure/Destination: Pamplona-Paris - Locomotive: Electric - Panorama: Fair - Speed: Medium - N.pieces: 4
Step Number: 4
Locomotive value: 0.1
Locomotive Route value: 0.4
Panorama value: 0.6
Speed value: 2
**********************

************  Method:  Means_End_For_Belief_Destination_Station *********: TReasoner_Function
******* Scenario_Number:    --1-- *******
Changed data at the END of the method:

No data is changed.
For the Desire --2-- The Attentional Goal is a:  TFunctional_Goal
Its Final belief type is: Belief_Destination_Station
Agent uses its Means_End_For_Belief_Destination_Station method to search some options

************  Method:  Means_End_For_Belief_Destination_Station *********: TReasoner_Function
******* Scenario_Number:    --1-- *******
Changed data at the BEGINNING of the method:

No data is changed.
*************** Work flow in Method ***************

The Functional_Goal Name is: Visit_Frankfurt
The Functional_Belief is a:  Belief_Destination_Station
I search for a plan for the Desire
I created/found some plan in Time: 3186 milliseconds
I found paths: 2376804
I found n. paths Before Finally_Formula: 2376804
I Apply the Finally Operator
Start time in simulation: 2024-10-01T16:00
Range time in Finally Operator - 2024-10-01T21:00 - 2024-10-01T23:00
I found n. paths After Finally_Formula: 0
Agent inserts actions to do (go to in some routes) in the desire. These can be null.
**** Path Steps ********
N. Options found : 0
Agent has not an option. Agent will have an intention with no option.

************  Method:  Means_End_For_Belief_Destination_Station *********: TReasoner_Function
******* Scenario_Number:    --1-- *******
Changed data at the END of the method:

No data is changed.
Now Agent will filter any desire.

************  Method:  Filtering_Process *********: TReasoner_Function
******* Scenario_Number:    --1-- *******
Changed data at the BEGINNING of the method:

No data is changed.
*************** Work flow in Method ***************
Agent filters the Desire with name: D1

Now I apply Green and Quality Goal filters

I apply Green filters
N. Green Goal for this desire: 1
Before resizing: 3
After resizing: 2
I found paths (options) After Green_Filter: 2

I apply Quality filters
N. Quality Goal for this desire: 1
--- I apply quality name: qg1
--- Value_Quality_Goal: great
I found paths (options) After Quality_Filter: 2
Functional Goal Name for the Desire is : Visit_Paris
N. Survival Options of the Desire: 2
I filtered and ordered found options ( 2 ) in Time: 1 milliseconds
Agent filters the Desire with name: D2

Now I apply Green and Quality Goal filters

I apply Green filters
N. Green Goal for this desire: 1
Before resizing: 0
After resizing: 0
I found paths (options) After Green_Filter: 0

I apply Quality filters
N. Quality Goal for this desire: 1
--- I apply quality name: qg1
--- Value_Quality_Goal: great
I found paths (options) After Quality_Filter: 0
Functional Goal Name for the Desire is : Visit_Frankfurt
N. Survival Options of the Desire: 0
I filtered and ordered found options ( 0 ) in Time: 0 milliseconds

************  Method:  Filtering_Process *********: TReasoner_Function
******* Scenario_Number:    --1-- *******
Changed data at the END of the method:

Desires in GW
N. Desires in GW: 2
Desire N. -1 - Named: D1
Desire N. -2 - Named: D2

Desires with Options in GW
Desire N. -1 - Named: D1 has N. Options: 2
Desire N. -2 - Named: D2 has N. Options: 0


************  Method:  MeansEnd *********: TReasoner_Function
******* Scenario_Number:    --1-- *******
Changed data at the END of the method:

No data is changed.

************  Method:  Deliberate_Process *********: TReasoner_Function
******* Scenario_Number:    --1-- *******
Changed data at the BEGINNING of the method:

Desires in GW
N. Desires in GW: 2
Desire N. -1 - Named: D1
Desire N. -2 - Named: D2

Desires with Options in GW
Desire N. -1 - Named: D1 has N. Options: 2
Desire N. -2 - Named: D2 has N. Options: 0

*************** Work flow in Method ***************
Now, Agent create an intention for any desire
Desire Functional Goal Name: Visit_Paris
Desire Options: 2

Desire Functional Goal Name: Visit_Frankfurt
Desire Options: 0


************  Method:  Update_Intentions *********: TGlobalWorkspace
******* Scenario_Number:    --1-- *******
Changed data at the BEGINNING of the method:

No data is changed.
*************** Work flow in Method ***************

************  Method:  Update_Intentions *********: TGlobalWorkspace
******* Scenario_Number:    --1-- *******
Changed data at the END of the method:

Intentions in GW
N. Intentions in GW: 2

The Agent updated its intentions correctly.

************  Method:  Deliberate_Process *********: TReasoner_Function
******* Scenario_Number:    --1-- *******
Changed data at the END of the method:

No data is changed.

************  Method:  Focus_Attention *********: TE_Inhibition_function
******* Scenario_Number:    --1-- *******
Changed data at the BEGINNING of the method:

Intentions in GW
N. Intentions in GW: 2

*************** Work flow in Method ***************
Functional Name for the Intention selected to pursue: Visit_Paris
Agent creates the Inhibition Regions

Agent creates the Inhibited Goals
Agent creates the Inhibited Beliefs
[Cara_Simulation.TBelief_Base@76f2b07d, Cara_Simulation.TBelief_Base@704a52ec, Cara_Simulation.TBelief_Base@6ee52dcd, Cara_Simulation.TBelief_Base@4493d195, Cara_Simulation.TBelief_Base@2781e022, Cara_Simulation.TBelief_Base@57e1b0c, Cara_Simulation.TSalient_Belief@4232c52b, Cara_Simulation.TSalient_Belief@1877ab81, Cara_Simulation.TSalient_Belief@305fd85d, Cara_Simulation.TSalient_Belief@458c1321, Cara_Simulation.TSalient_Belief@11438d26, Cara_Simulation.TSalient_Belief@34cd072c, Cara_Simulation.TBelief_Base@7a1ebcd8]
[Cara_Simulation.TBelief_Base@5faeada1, Cara_Simulation.TBelief_Base@704a52ec, Cara_Simulation.TBelief_Base@6ee52dcd, Cara_Simulation.TBelief_Base@4493d195, Cara_Simulation.TBelief_Base@2781e022, Cara_Simulation.TBelief_Base@57e1b0c, Cara_Simulation.TSalient_Belief@4232c52b, Cara_Simulation.TSalient_Belief@1877ab81, Cara_Simulation.TSalient_Belief@305fd85d, Cara_Simulation.TSalient_Belief@458c1321, Cara_Simulation.TSalient_Belief@11438d26, Cara_Simulation.TSalient_Belief@34cd072c, Cara_Simulation.TBelief_Base@528931cf]

************  Method:  Focus_Attention *********: TE_Inhibition_function
******* Scenario_Number:    --1-- *******
Changed data at the END of the method:

No data is changed.

************  Method:  Plan_Advanc_Eval *********: TResource_Allocation
******* Scenario_Number:    --1-- *******
Changed data at the BEGINNING of the method:

Beliefs in GW:
N. UnInhibited Beliefs in GW: 15

Beliefs in LONG MEMORY:
N. Belief in LONG MEMORY: 67
N. Inhibited Beliefs in LONG MEMORY: 52

*************** Work flow in Method ***************
Agent acts an action for the intention with Functional Name: Visit_Paris
Agent checks if preconditions for the actions are correct:
Current Station is: Lisboa
Current Route is: -1
Current Step is: 0
Precondition Station is: Lisboa
Precondition Route is: -1
Precondition Stepis: 0
Yes, Precondition of the action are correct!
I execute the action

************  Method:  Plan_Exec *********: TResource_Allocation
******* Scenario_Number:    --1-- *******
Changed data at the BEGINNING of the method:

No data is changed.
*************** Work flow in Method ***************
Agent executes an action:
Invoked Function for the Action: GO_TO_Route
Response_Number: 0
Request: GO_TO_Route

************  Method:  Plan_Exec *********: TResource_Allocation
******* Scenario_Number:    --1-- *******
Changed data at the END of the method:

No data is changed.

************  Method:  Plan_Advanc_Eval *********: TResource_Allocation
******* Scenario_Number:    --1-- *******
Changed data at the END of the method:

No data is changed.
Working_Cycle; 1

************  Method:  Perception_Processing *********: TWorking_Memory_Maintenance
******* Scenario_Number:    --1-- *******
Changed data at the BEGINNING of the method:

No data is changed.
*************** Work flow in Method ***************
Perception Processing number: 1
I'm feeling some stimulus
Sensor acquires last Perception (if it exists).
Perception acquired correctly.
WMM analyzes perception.
I update several information in Beliefs and in plan actions
I Update Position Beliefs:
from Previous Current_Station: Lisboa
from Previous Current_Route: -1
from Previous Current_Step: 0

to Updated Current_Station: Lisboa
to Updated Current_Route: 128
to Updated Current_Step: 3

************  Method:  Update_Belief_by_Stimulus *********: TGlobalWorkspace
******* Scenario_Number:    --1-- *******
Changed data at the BEGINNING of the method:

No data is changed.
*************** Work flow in Method ***************

************  Method:  Update_Belief_by_Stimulus *********: TGlobalWorkspace
******* Scenario_Number:    --1-- *******
Changed data at the END of the method:

No data is changed.
The Agent has a stimulus and checks if it has a saliency greater then Saliency/Attention threholds of the agent.

************  Method:  AM_Exogenous_Module *********: TE_Switching_Function
******* Scenario_Number:    --1-- *******
Changed data at the BEGINNING of the method:

Beliefs in GW:
N. UnInhibited Beliefs in GW: 15

Beliefs in LONG MEMORY:
N. Belief in LONG MEMORY: 67
N. Inhibited Beliefs in LONG MEMORY: 52

*************** Work flow in Method ***************

************  Method:  Plan_Advanc_Eval *********: TResource_Allocation
******* Scenario_Number:    --1-- *******
Changed data at the BEGINNING of the method:

No data is changed.
*************** Work flow in Method ***************
Agent acts an action for the intention with Functional Name: Visit_Paris
Agent checks if preconditions for the actions are correct:
Current Station is: Lisboa
Current Route is: 128
Current Step is: 3
Precondition Station is: Lisboa
Precondition Route is: 128
Precondition Stepis: 3
Yes, Precondition of the action are correct!
I execute the action

************  Method:  Plan_Exec *********: TResource_Allocation
******* Scenario_Number:    --1-- *******
Changed data at the BEGINNING of the method:

No data is changed.
*************** Work flow in Method ***************
Agent executes an action:
Invoked Function for the Action: GO_TO_Step
Response_Number: 1
Request: GO_TO_Step

************  Method:  Plan_Exec *********: TResource_Allocation
******* Scenario_Number:    --1-- *******
Changed data at the END of the method:

No data is changed.

************  Method:  Plan_Advanc_Eval *********: TResource_Allocation
******* Scenario_Number:    --1-- *******
Changed data at the END of the method:

No data is changed.
Working_Cycle; 2

************  Method:  Perception_Processing *********: TWorking_Memory_Maintenance
******* Scenario_Number:    --1-- *******
Changed data at the BEGINNING of the method:

No data is changed.
*************** Work flow in Method ***************
Perception Processing number: 2
I'm feeling some stimulus
Sensor acquires last Perception (if it exists).
Perception acquired correctly.
WMM analyzes perception.
I update several information in Beliefs and in plan actions
I Update Position Beliefs:
from Previous Current_Station: Lisboa
from Previous Current_Route: 128
from Previous Current_Step: 3

to Updated Current_Station: Madrid
to Updated Current_Route: -1
to Updated Current_Step: 0

************  Method:  Update_Belief_by_Stimulus *********: TGlobalWorkspace
******* Scenario_Number:    --1-- *******
Changed data at the BEGINNING of the method:

No data is changed.
*************** Work flow in Method ***************

************  Method:  Update_Belief_by_Stimulus *********: TGlobalWorkspace
******* Scenario_Number:    --1-- *******
Changed data at the END of the method:

No data is changed.
The Agent has a stimulus and checks if it has a saliency greater then Saliency/Attention threholds of the agent.

************  Method:  AM_Exogenous_Module *********: TE_Switching_Function
******* Scenario_Number:    --1-- *******
Changed data at the BEGINNING of the method:

Beliefs in GW:
N. UnInhibited Beliefs in GW: 15

Beliefs in LONG MEMORY:
N. Belief in LONG MEMORY: 67
N. Inhibited Beliefs in LONG MEMORY: 52

*************** Work flow in Method ***************

************  Method:  Plan_Advanc_Eval *********: TResource_Allocation
******* Scenario_Number:    --1-- *******
Changed data at the BEGINNING of the method:

No data is changed.
*************** Work flow in Method ***************
Agent acts an action for the intention with Functional Name: Visit_Paris
Agent checks if preconditions for the actions are correct:
Current Station is: Madrid
Current Route is: -1
Current Step is: 0
Precondition Station is: Madrid
Precondition Route is: -1
Precondition Stepis: 0
Yes, Precondition of the action are correct!
I execute the action

************  Method:  Plan_Exec *********: TResource_Allocation
******* Scenario_Number:    --1-- *******
Changed data at the BEGINNING of the method:

No data is changed.
*************** Work flow in Method ***************
Agent executes an action:
Invoked Function for the Action: GO_TO_Route
Response_Number: 2
Request: GO_TO_Route

************  Method:  Plan_Exec *********: TResource_Allocation
******* Scenario_Number:    --1-- *******
Changed data at the END of the method:

No data is changed.

************  Method:  Plan_Advanc_Eval *********: TResource_Allocation
******* Scenario_Number:    --1-- *******
Changed data at the END of the method:

No data is changed.
Working_Cycle; 3

************  Method:  Perception_Processing *********: TWorking_Memory_Maintenance
******* Scenario_Number:    --1-- *******
Changed data at the BEGINNING of the method:

No data is changed.
*************** Work flow in Method ***************
Perception Processing number: 3
I'm feeling some stimulus
Sensor acquires last Perception (if it exists).
Perception acquired correctly.
WMM analyzes perception.
I update several information in Beliefs and in plan actions
I Update Position Beliefs:
from Previous Current_Station: Madrid
from Previous Current_Route: -1
from Previous Current_Step: 0

to Updated Current_Station: Madrid
to Updated Current_Route: 144
to Updated Current_Step: 2

************  Method:  Update_Belief_by_Stimulus *********: TGlobalWorkspace
******* Scenario_Number:    --1-- *******
Changed data at the BEGINNING of the method:

No data is changed.
*************** Work flow in Method ***************

************  Method:  Update_Belief_by_Stimulus *********: TGlobalWorkspace
******* Scenario_Number:    --1-- *******
Changed data at the END of the method:

No data is changed.
The Agent has a stimulus and checks if it has a saliency greater then Saliency/Attention threholds of the agent.

************  Method:  AM_Exogenous_Module *********: TE_Switching_Function
******* Scenario_Number:    --1-- *******
Changed data at the BEGINNING of the method:

Beliefs in GW:
N. UnInhibited Beliefs in GW: 15

Beliefs in LONG MEMORY:
N. Belief in LONG MEMORY: 67
N. Inhibited Beliefs in LONG MEMORY: 52

*************** Work flow in Method ***************

************  Method:  Plan_Advanc_Eval *********: TResource_Allocation
******* Scenario_Number:    --1-- *******
Changed data at the BEGINNING of the method:

No data is changed.
*************** Work flow in Method ***************
Agent acts an action for the intention with Functional Name: Visit_Paris
Agent checks if preconditions for the actions are correct:
Current Station is: Madrid
Current Route is: 144
Current Step is: 2
Precondition Station is: Madrid
Precondition Route is: 144
Precondition Stepis: 2
Yes, Precondition of the action are correct!
I execute the action

************  Method:  Plan_Exec *********: TResource_Allocation
******* Scenario_Number:    --1-- *******
Changed data at the BEGINNING of the method:

No data is changed.
*************** Work flow in Method ***************
Agent executes an action:
Invoked Function for the Action: GO_TO_Step
Response_Number: 3
Request: GO_TO_Step

************  Method:  Plan_Exec *********: TResource_Allocation
******* Scenario_Number:    --1-- *******
Changed data at the END of the method:

No data is changed.

************  Method:  Plan_Advanc_Eval *********: TResource_Allocation
******* Scenario_Number:    --1-- *******
Changed data at the END of the method:

No data is changed.
Working_Cycle; 4

************  Method:  Perception_Processing *********: TWorking_Memory_Maintenance
******* Scenario_Number:    --1-- *******
Changed data at the BEGINNING of the method:

No data is changed.
*************** Work flow in Method ***************
Perception Processing number: 4
I'm feeling some stimulus
Sensor acquires last Perception (if it exists).
Perception acquired correctly.
WMM analyzes perception.
I update several information in Beliefs and in plan actions
I Update Position Beliefs:
from Previous Current_Station: Madrid
from Previous Current_Route: 144
from Previous Current_Step: 2

to Updated Current_Station: Pamplona
to Updated Current_Route: -1
to Updated Current_Step: 0

************  Method:  Update_Belief_by_Stimulus *********: TGlobalWorkspace
******* Scenario_Number:    --1-- *******
Changed data at the BEGINNING of the method:

No data is changed.
*************** Work flow in Method ***************

************  Method:  Update_Belief_by_Stimulus *********: TGlobalWorkspace
******* Scenario_Number:    --1-- *******
Changed data at the END of the method:

No data is changed.
End Simulation.
